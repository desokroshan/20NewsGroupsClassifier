{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism',\n",
      " 'comp.graphics',\n",
      " 'comp.os.ms-windows.misc',\n",
      " 'comp.sys.ibm.pc.hardware',\n",
      " 'comp.sys.mac.hardware',\n",
      " 'comp.windows.x',\n",
      " 'misc.forsale',\n",
      " 'rec.autos',\n",
      " 'rec.motorcycles',\n",
      " 'rec.sport.baseball',\n",
      " 'rec.sport.hockey',\n",
      " 'sci.crypt',\n",
      " 'sci.electronics',\n",
      " 'sci.med',\n",
      " 'sci.space',\n",
      " 'soc.religion.christian',\n",
      " 'talk.politics.guns',\n",
      " 'talk.politics.mideast',\n",
      " 'talk.politics.misc',\n",
      " 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "news_groups_train = fetch_20newsgroups(subset='train')\n",
    "from pprint import pprint\n",
    "pprint(list(news_groups_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "Organization: The City University\n",
      "Lines: 14\n",
      "\n",
      "Does anyone know of a good way (standard PC application/PD utility) to\n",
      "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
      "do the same, converting to HPGL (HP plotter) files.\n",
      "\n",
      "Please email any response.\n",
      "\n",
      "Is this the correct group?\n",
      "\n",
      "Thanks in advance.  Michael.\n",
      "-- \n",
      "Michael Collier (Programmer)                 The Computer Unit,\n",
      "Email: M.P.Collier@uk.ac.city                The City University,\n",
      "Tel: 071 477-8000 x3769                      London,\n",
      "Fax: 071 477-8565                            EC1V 0HB.\n",
      "\n",
      "comp.graphics\n",
      "2257\n",
      "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']\n",
      "[1 1 3 3 3 3 3 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# lets work on a subset of entire data for faster execution\n",
    "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']\n",
    "# the dataset\n",
    "partial_data = fetch_20newsgroups(subset='train', categories=categories,shuffle=True, random_state=42)\n",
    "\n",
    "# Exploration\n",
    "print(\"\\n\".join(partial_data.data[0].split('\\n')[:]))\n",
    "print(partial_data.target_names[partial_data.target[0]])\n",
    "print(len(partial_data.data)) # Number of documents in our system\n",
    "print(partial_data.target_names) # Distinct classes(categories) of the documents\n",
    "print(partial_data.target[:10]) # target contains indices of the target_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2257, 35788)\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction\n",
    "# CountVectorizer does TextPreprocessing, tokenizing and filtering of stopwords.\n",
    "# It finally 1. builds a dictionary of features and and 2. transforms the documents into feature vectors\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_count = count_vect.fit_transform(partial_data.data)\n",
    "print(X_train_count.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partial_data.data, a list of 2257 documents;Each of the document was converted into its bag-of-word vector representation.  \n",
    "Length of the vocabalury is 35788"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2257, 35788)\n"
     ]
    }
   ],
   "source": [
    "# Working on Improving the features\n",
    "# Better than counts are the frequencies of occurence of words\n",
    "# Better than frequencies are tF-idf(term frequency times inverse Document Frequency)\n",
    "# Count can be converted to tf-idf with standard sklearn package\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_count)\n",
    "print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Naive Bayesian Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['soc.religion.christian', 'comp.graphics']\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, partial_data.target)\n",
    "# Predict\n",
    "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
    "X_test_count = count_vect.transform(docs_new)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_count)\n",
    "predicted = clf.predict(X_test_tfidf)\n",
    "predictions = [partial_data.target_names[pred] for pred in predicted]\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.834886817577\n"
     ]
    }
   ],
   "source": [
    "# alternate way of designing a compound classifier pipeline\n",
    "# Evaluating Model Performance on test set\n",
    "import numpy as np\n",
    "test_data = fetch_20newsgroups(subset='test',categories=categories,shuffle=True,random_state=42)\n",
    "X_test_count = count_vect.transform(test_data.data)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_count)\n",
    "predicted=clf.predict(X_test_tfidf)\n",
    "print(np.mean(predicted==test_data.target))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Better Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9127829560585885"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attempts to improve the accuracy\n",
    "# Use SVM instead of naive Baye's classifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "#  Here we combine the above steps of feature extraction and calssifier into a single pipeline using\n",
    "# pre-defined methods in sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Initialize the text classifier\n",
    "text_clf = Pipeline([('vect',CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge',penalty='l2', alpha=1e-3, n_iter=5, random_state=42))])\n",
    "_ = text_clf.fit(partial_data.data,partial_data.target)\n",
    "predicted = text_clf.predict(test_data.data)\n",
    "np.mean(predicted == test_data.target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
